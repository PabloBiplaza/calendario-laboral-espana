# ü§ù Gu√≠a de Contribuci√≥n

## C√≥mo A√±adir una Nueva CCAA

Esta gu√≠a explica paso a paso c√≥mo a√±adir soporte para una nueva comunidad aut√≥noma.

### Ejemplo: A√±adir Valencia

---

## PASO 1: Investigar Fuentes Oficiales

### 1.1 Encontrar el Bolet√≠n Oficial

Buscar el bolet√≠n oficial de la CCAA:
- **Valencia**: DOGV (Diari Oficial de la Generalitat Valenciana)
- **Catalu√±a**: DOGC (Diari Oficial de la Generalitat de Catalunya)
- **Andaluc√≠a**: BOJA (Bolet√≠n Oficial de la Junta de Andaluc√≠a)

### 1.2 Encontrar Publicaciones Recientes

Web search: `site:dogv.gva.es fiestas laborales 2025`

Identificar:
- **Tipo de documento**: Decreto, Orden, Resoluci√≥n
- **Fecha de publicaci√≥n**: ¬øCu√°ndo se publica? (septiembre, octubre, diciembre)
- **URL pattern**: ¬øC√≥mo est√°n estructuradas las URLs?

**Ejemplo Valencia:**
```
Auton√≥micos: Decreto del Consell (septiembre)
URL: https://www.dogv.gva.es/datos/2024/09/25/pdf/2024_8765.pdf

Locales: Resoluci√≥n (diciembre)
URL: https://www.dogv.gva.es/datos/2024/12/15/pdf/2024_10234.pdf
```

---

## PASO 2: Crear Estructura de Directorios

```bash
mkdir -p scrapers/ccaa/valencia
touch scrapers/ccaa/valencia/__init__.py
touch scrapers/ccaa/valencia/autonomicos.py
touch scrapers/ccaa/valencia/locales.py
```

---

## PASO 3: Implementar Scraper de Auton√≥micos

### 3.1 Template B√°sico

**scrapers/ccaa/valencia/autonomicos.py:**

```python
"""
Scraper de festivos auton√≥micos de Valencia desde el DOGV
"""

from typing import Dict, List, Optional
from scrapers.core.base_scraper import CCAAAutonomicosScraper
import re
from datetime import datetime


class ValenciaAutonomicosScraper(CCAAAutonomicosScraper):
    """
    Extrae festivos auton√≥micos de la Comunidad Valenciana
    desde el DOGV (Diari Oficial de la Generalitat Valenciana)
    """
    
    # URLs conocidas (a√±adir seg√∫n se vayan publicando)
    KNOWN_URLS = {
        2025: "https://www.dogv.gva.es/datos/2024/09/25/pdf/2024_8765.pdf",
        # A√±adir m√°s a√±os seg√∫n se publiquen
    }
    
    # Archivo de cache
    CACHE_FILE = 'config/valencia_urls_cache.json'
    
    def __init__(self, year: int):
        super().__init__(year=year, ccaa='valencia', tipo='autonomicos')
        self._load_cache()
    
    def get_source_url(self) -> str:
        """
        Obtiene la URL de la fuente oficial
        
        Niveles:
        1. KNOWN_URLS (hardcoded)
        2. Cache (descubierto previamente)
        3. Auto-discovery (si existe)
        """
        
        # Nivel 1: KNOWN_URLS
        if self.year in self.KNOWN_URLS:
            print(f"‚úÖ URL oficial (KNOWN_URLS) para {self.year}: {self.KNOWN_URLS[self.year]}")
            return self.KNOWN_URLS[self.year]
        
        # Nivel 2: Cache
        if self.year in self.cache.get('autonomicos', {}):
            url = self.cache['autonomicos'][self.year]
            print(f"üì¶ URL en cache para {self.year}: {url}")
            return url
        
        # Nivel 3: Auto-discovery (implementar si es posible)
        # TODO: Implementar auto_discover_valencia()
        
        raise ValueError(
            f"‚ùå No se pudo encontrar URL para festivos auton√≥micos Valencia {self.year}\n"
            f"   A√±ade manualmente la URL en KNOWN_URLS o cache."
        )
    
    def parse_festivos(self, content: str) -> List[Dict]:
        """
        Parsea festivos desde el contenido del DOGV
        
        IMPORTANTE: Adaptar seg√∫n el formato real del DOGV
        """
        print(f"üîç Parseando festivos auton√≥micos de Valencia...")
        
        festivos = []
        
        # TODO: Implementar parsing espec√≠fico del DOGV
        # Ejemplo gen√©rico:
        
        # Buscar fechas en formato "dd de mes de yyyy"
        patron_fecha = r'(\d{1,2})\s+de\s+(\w+)\s+de\s+(\d{4})'
        matches = re.finditer(patron_fecha, content, re.IGNORECASE)
        
        meses = {
            'enero': 1, 'febrero': 2, 'marzo': 3, 'abril': 4,
            'mayo': 5, 'junio': 6, 'julio': 7, 'agosto': 8,
            'septiembre': 9, 'octubre': 10, 'noviembre': 11, 'diciembre': 12
        }
        
        for match in matches:
            dia = int(match.group(1))
            mes_texto = match.group(2).lower()
            year = int(match.group(3))
            
            if year == self.year and mes_texto in meses:
                mes = meses[mes_texto]
                fecha_iso = f"{year:04d}-{mes:02d}-{dia:02d}"
                
                # Extraer descripci√≥n (adaptar seg√∫n formato real)
                # ...
                
                festivos.append({
                    'fecha': fecha_iso,
                    'descripcion': 'Festivo auton√≥mico',  # TODO: Extraer descripci√≥n real
                    'tipo': 'autonomico',
                    'ambito': 'autonomico',
                    'sustituible': False,
                    'year': self.year
                })
        
        print(f"   ‚úÖ Extra√≠dos {len(festivos)} festivos auton√≥micos")
        return festivos
    
    def _load_cache(self):
        """Carga URLs del cache"""
        import os
        import json
        
        self.cache = {'autonomicos': {}, 'locales': {}}
        
        if os.path.exists(self.CACHE_FILE):
            try:
                with open(self.CACHE_FILE, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                print(f"üì¶ Cache cargado: {len(self.cache.get('autonomicos', {}))} URLs auton√≥micas")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error cargando cache: {e}")


# Test individual
if __name__ == "__main__":
    import sys
    
    year = int(sys.argv[1]) if len(sys.argv) > 1 else 2025
    
    print("=" * 80)
    print(f"üß™ TEST: Valencia Auton√≥micos Scraper - Festivos {year}")
    print("=" * 80)
    
    scraper = ValenciaAutonomicosScraper(year=year)
    festivos = scraper.scrape()
    
    # Mostrar resumen
    scraper.print_summary(festivos)
    
    # Guardar
    scraper.save_to_json(festivos, f'data/valencia_autonomicos_{year}.json')
    scraper.save_to_excel(festivos, f'data/valencia_autonomicos_{year}.xlsx')
```

### 3.2 Adaptar el Parser

**CR√çTICO:** El m√©todo `parse_festivos()` debe adaptarse al formato espec√≠fico del bolet√≠n oficial.

**Pasos:**
1. Descargar un PDF/HTML de ejemplo
2. Analizar la estructura
3. Crear expresiones regulares espec√≠ficas
4. Probar con varios a√±os

**Ejemplo de formatos comunes:**

```python
# Formato 1: Lista numerada
"""
1. 1 de enero - A√±o Nuevo
2. 6 de enero - Epifan√≠a del Se√±or
...
"""
patron = r'(\d+)\.\s+(\d{1,2})\s+de\s+(\w+)\s+-\s+([^\n]+)'

# Formato 2: Tabla
"""
| Fecha       | Festividad          |
|-------------|---------------------|
| 1 de enero  | A√±o Nuevo          |
"""
# Usar Beautiful Soup para parsear tablas HTML

# Formato 3: P√°rrafos
"""
Art√≠culo 1. Se establecen como festivos:
El d√≠a 1 de enero (A√±o Nuevo), el 6 de enero (Epifan√≠a)...
"""
patron = r'(\d{1,2})\s+de\s+(\w+)\s+\(([^)]+)\)'
```

---

## PASO 4: Implementar Scraper de Locales

Similar al de auton√≥micos, pero filtrando por municipio:

**scrapers/ccaa/valencia/locales.py:**

```python
class ValenciaLocalesScraper(CCAALocalesScraper):
    def __init__(self, municipio: str, year: int):
        super().__init__(year=year, ccaa='valencia', municipio=municipio, tipo='locales')
        self._load_cache()
    
    def parse_festivos(self, content: str) -> List[Dict]:
        """
        Parsea festivos locales
        
        Formato t√≠pico:
        ‚Äî Valencia: 9 de octubre y 19 de marzo
        ‚Äî Alicante: 24 de junio y 29 de junio
        """
        
        festivos = []
        
        # Buscar l√≠neas con municipio
        patron = r'‚Äî\s*([^:]+):\s*([^.\n]+)'
        matches = re.finditer(patron, content)
        
        for match in matches:
            nombre_municipio = match.group(1).strip()
            fechas_texto = match.group(2).strip()
            
            # Filtrar por municipio
            if self.municipio.lower() not in nombre_municipio.lower():
                continue
            
            # Extraer fechas del texto
            # ...
            
        return festivos
```

---

## PASO 5: Crear Cache

**config/valencia_urls_cache.json:**

```json
{
  "autonomicos": {
    "2025": "https://www.dogv.gva.es/datos/2024/09/25/pdf/2024_8765.pdf"
  },
  "locales": {
    "2025": "https://www.dogv.gva.es/datos/2024/12/15/pdf/2024_10234.pdf"
  }
}
```

---

## PASO 6: Integrar en Scraper Unificado

**scrape_municipio.py:**

```python
# A√±adir en la funci√≥n scrape_festivos_completos()

elif ccaa.lower() == 'valencia':
    # Auton√≥micos
    from scrapers.ccaa.valencia.autonomicos import ValenciaAutonomicosScraper
    scraper_auto = ValenciaAutonomicosScraper(year=year)
    festivos_autonomicos = scraper_auto.scrape()
    
    # Locales
    from scrapers.ccaa.valencia.locales import ValenciaLocalesScraper
    scraper_local = ValenciaLocalesScraper(municipio=municipio, year=year)
    festivos_locales = scraper_local.scrape()
```

---

## PASO 7: Testing

### 7.1 Test Individual Auton√≥micos

```bash
python -m scrapers.ccaa.valencia.autonomicos 2025
```

**Verificar:**
- ‚úÖ Descarga correctamente
- ‚úÖ Parsea festivos
- ‚úÖ N√∫mero correcto de festivos (t√≠picamente 10-12)

### 7.2 Test Individual Locales

```bash
python -m scrapers.ccaa.valencia.locales "Valencia" 2025
```

**Verificar:**
- ‚úÖ Encuentra el municipio
- ‚úÖ Extrae 2 festivos locales

### 7.3 Test Unificado

```bash
python scrape_municipio.py "Valencia" valencia 2025
```

**Verificar:**
- ‚úÖ Total: 14 festivos (11-12 √∫nicos tras eliminar duplicados)
- ‚úÖ Sin duplicados
- ‚úÖ JSON y Excel generados

---

## PASO 8: Documentaci√≥n

Actualizar README.md:

```markdown
## ‚úÖ Implementado

- **Valencia**: Sistema completo
  - Festivos auton√≥micos
  - Festivos locales (540 municipios)
  - A√±os disponibles: 2025
```

---

## PASO 9: Auto-Discovery (Opcional)

Si el bolet√≠n oficial tiene b√∫squeda web, implementar:

**scrapers/discovery/ccaa/valencia_discovery.py:**

```python
def auto_discover_valencia(year: int) -> Dict[str, str]:
    """
    Busca autom√°ticamente publicaciones en el DOGV
    """
    
    # Estrategia 1: Web search
    query = f"site:dogv.gva.es fiestas laborales {year}"
    
    # Estrategia 2: Scraping de √≠ndices
    # ...
    
    # Estrategia 3: API si existe
    # ...
```

---

## PASO 10: Pull Request

### 10.1 Commit

```bash
git add .
git commit -m "feat: a√±adir soporte para Valencia

- Scraper de festivos auton√≥micos
- Scraper de festivos locales (540 municipios)
- Cache para 2025
- Tests pasando
- Documentaci√≥n actualizada"
```

### 10.2 PR Description

```markdown
## A√±adir soporte para Valencia

### ‚úÖ Implementado
- Festivos auton√≥micos desde DOGV
- Festivos locales (540 municipios)
- Parser adaptado al formato del DOGV
- Cache inicial: 2025

### üß™ Tests
- [x] Auton√≥micos: 10 festivos extra√≠dos
- [x] Locales Valencia: 2 festivos extra√≠dos
- [x] Unificado: 14 festivos totales
- [x] Sin duplicados

### üìù Formato del DOGV
- Auton√≥micos: Decreto del Consell (septiembre)
- Locales: Resoluci√≥n (diciembre)
- Parser: Expresiones regulares adaptadas

### ‚è≥ Pendiente
- Auto-discovery (DOGV tiene protecci√≥n anti-scraping)
```

---

## Checklist de Nueva CCAA

- [ ] Investigar fuente oficial
- [ ] Identificar patr√≥n de URLs
- [ ] Crear estructura de directorios
- [ ] Implementar scraper auton√≥micos
- [ ] Implementar scraper locales
- [ ] Adaptar parsers al formato espec√≠fico
- [ ] Crear archivo de cache
- [ ] Integrar en scraper unificado
- [ ] Tests individuales pasando
- [ ] Test unificado pasando
- [ ] Documentaci√≥n actualizada
- [ ] (Opcional) Implementar auto-discovery
- [ ] Commit y PR

---

## Recursos √ötiles

### Boletines Oficiales de CCAA

| CCAA | Bolet√≠n | URL |
|------|---------|-----|
| Andaluc√≠a | BOJA | https://www.juntadeandalucia.es/boja |
| Arag√≥n | BOA | https://www.boa.aragon.es |
| Asturias | BOPA | https://sede.asturias.es/bopa |
| Baleares | BOIB | https://www.caib.es/boib |
| Canarias | BOC | https://www.gobiernodecanarias.org/boc |
| Cantabria | BOC | https://boc.cantabria.es |
| Castilla y Le√≥n | BOCYL | https://bocyl.jcyl.es |
| Castilla-La Mancha | DOCM | https://docm.jccm.es |
| Catalu√±a | DOGC | https://dogc.gencat.cat |
| Extremadura | DOE | https://doe.juntaex.es |
| Galicia | DOG | https://www.xunta.gal/diario-oficial-galicia |
| Madrid | BOCM | https://www.bocm.es |
| Murcia | BORM | https://www.borm.es |
| Navarra | BON | https://bon.navarra.es |
| Pa√≠s Vasco | BOPV | https://www.euskadi.eus/bopv2 |
| La Rioja | BOR | https://web.larioja.org/bor |
| Valencia | DOGV | https://www.dogv.gva.es |

### Herramientas de Desarrollo

```bash
# Ver contenido de PDF
pdftotext documento.pdf - | less

# Extraer texto limpio
python -c "import pdfplumber; print(pdfplumber.open('doc.pdf').pages[0].extract_text())"

# Test regex
python -c "import re; print(re.findall(r'tu_patron', 'texto_prueba'))"

# Ver encoding
file -I documento.txt
```

### Patrones Comunes

```python
# Fechas espa√±ol
r'(\d{1,2})\s+de\s+(enero|febrero|...|diciembre)'

# Municipios
r'‚Äî\s*([^:]+):\s*([^.\n]+)'

# Descripciones
r'([A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±\s]+)'

# Normalizar texto
import unicodedata
texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')
```

---

## Preguntas Frecuentes

### ¬øQu√© hacer si el PDF no se puede parsear?

1. Probar con `pdfplumber` en lugar de `PyPDF2`
2. Usar OCR si es imagen: `pytesseract`
3. Convertir PDF ‚Üí HTML: herramientas online

### ¬øC√≥mo manejar formatos inconsistentes?

Implementar m√∫ltiples patrones y probar en orden:

```python
for patron in [patron1, patron2, patron3]:
    matches = re.finditer(patron, content)
    if matches:
        return parse_matches(matches)
```

### ¬øQu√© hacer si hay actualizaciones del bolet√≠n?

El mismo bolet√≠n puede tener correcciones:

```python
# Buscar "modificaci√≥n", "correcci√≥n"
# Aplicar cambios sobre datos anteriores
```

---

¬°Gracias por contribuir! üéâ
